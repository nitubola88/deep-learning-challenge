{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import libraries and read the data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        EIN                                      NAME APPLICATION_TYPE  \\\n",
      "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
      "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
      "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
      "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
      "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
      "\n",
      "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
      "0       Independent          C1000    ProductDev   Association       1   \n",
      "1       Independent          C2000  Preservation  Co-operative       1   \n",
      "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
      "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
      "4       Independent          C1000     Heathcare         Trust       1   \n",
      "\n",
      "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
      "0              0                      N     5000              1  \n",
      "1         1-9999                      N   108590              1  \n",
      "2              0                      N     5000              0  \n",
      "3    10000-24999                      N     6692              1  \n",
      "4  100000-499999                      N   142590              1  \n"
     ]
    }
   ],
   "source": [
    "# Load charity data from the provided URL\n",
    "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
    "\n",
    "# Inspect the data\n",
    "print(application_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Drop columns that aren't relevant for prediction\n",
    "application_df = application_df.drop(columns=[\"EIN\", \"NAME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Encode categorical variables using One-Hot Encoding for columns with multiple categories\n",
    "application_df = pd.get_dummies(application_df, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Handle missing values (if any) - filling or dropping\n",
    "# Check for missing values\n",
    "if application_df.isnull().sum().any():\n",
    "    application_df = application_df.dropna()  # Drop rows with missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Split the data into features (X) and target (y)\n",
    "X = application_df.drop(columns=[\"IS_SUCCESSFUL\"])\n",
    "y = application_df[\"IS_SUCCESSFUL\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " #Step 7: Define the model-building function with hyperparameter tuning\n",
    "def build_model(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # Hyperparameter for the first hidden layer units\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=hp.Int('units_1', min_value=32, max_value=256, step=32),\n",
    "        activation=hp.Choice('activation', values=['relu', 'tanh']),\n",
    "        input_dim=X_train.shape[1]\n",
    "    ))\n",
    "\n",
    "    # Hyperparameter for adding additional layers\n",
    "    for i in range(hp.Int('num_layers', 1, 4)):\n",
    "        model.add(tf.keras.layers.Dense(\n",
    "            units=hp.Int(f'units_{i+2}', min_value=32, max_value=256, step=32),\n",
    "            activation=hp.Choice('activation', values=['relu', 'tanh'])\n",
    "        ))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=hp.Choice('optimizer', values=['adam', 'sgd']),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nitub\\anaconda31\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Initialize Keras Tuner with Hyperband\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=10,\n",
    "    factor=3,\n",
    "    hyperband_iterations=1,\n",
    "    directory='my_dir',\n",
    "    project_name='charity_tuning'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 13s]\n",
      "val_accuracy: 0.7279883623123169\n",
      "\n",
      "Best val_accuracy So Far: 0.731195330619812\n",
      "Total elapsed time: 00h 03m 13s\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Run the tuner to search for the best hyperparameters\n",
    "tuner.search(X_train_scaled, y_train, epochs=10, validation_data=(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Get the best model\n",
    "best_model = tuner.get_best_models(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 - 0s - 2ms/step - accuracy: 0.7312 - loss: 0.5526\n",
      "Test Loss: 0.5526480078697205\n",
      "Test Accuracy: 0.731195330619812\n"
     ]
    }
   ],
   "source": [
    "# Step 11: Evaluate the best model on the test dataset\n",
    "loss, accuracy = best_model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "{'units_1': 64, 'activation': 'relu', 'num_layers': 2, 'units_2': 256, 'optimizer': 'adam', 'units_3': 128, 'units_4': 192, 'units_5': 64, 'tuner/epochs': 10, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n"
     ]
    }
   ],
   "source": [
    "# Step 12: Get the best hyperparameters\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(1)[0]\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(best_hyperparameters.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved as 'best_charity_model.h5'\n"
     ]
    }
   ],
   "source": [
    "# Step 13: Save the best model\n",
    "best_model.save('best_charity_model.h5')\n",
    "print(\"Best model saved as 'best_charity_model.h5'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
